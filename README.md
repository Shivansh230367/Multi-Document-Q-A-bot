# Multi-Document-Q-A-bot
This project implements a **Retrieval-Augmented Generation (RAG)** pipeline using **FastAPI** and **ChromaDB**.  
It allows users to upload and query their own documents to get **context-aware answers** powered by **GPT** or **Gemini** language models.

---

## ğŸš€ Features

- ğŸ“‚ Upload up to **20 PDF or text files** (each up to 1000 pages)
- ğŸ§© Automatic text chunking and vector embedding generation
- ğŸ§  Storage and retrieval using **ChromaDB**
- ğŸ’¬ Intelligent question answering with **GPT** or **Gemini**
- âš¡ Fast and lightweight backend built with **FastAPI**
- ğŸŒ Ready for deployment via **Uvicorn** or **Ngrok**

---

## ğŸ§  Tech Stack

### Backend: 
FastAPI

### Database: 
ChromaDB

### Embeddings: 
Sentence Transformers

### Models: 
GPT / Gemini

File Handling: PyPDF2, aiofiles

Deployment: Uvicorn, Ngrok
